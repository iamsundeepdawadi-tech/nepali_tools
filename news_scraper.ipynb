{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3c04f7",
   "metadata": {},
   "source": [
    "https://www.npmjs.com/package/nepali-news-scraper?activeTab=code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321ccbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eKantipur बाट 5 वटा समाचार स्क्र्याप गरिँदैछ (https://ekantipur.com/news)...\n",
      "विवरण स्क्र्याप गरिँदैछ: https://ekantipur.com/news/2025/09/12/202509121757688678.html\n",
      "विवरण स्क्र्याप गरिँदैछ: https://ekantipur.com/news/2025/09/12/202509121757679700.html\n",
      "विवरण स्क्र्याप गरिँदैछ: https://ekantipur.com/news/2025/09/12/202509121757676495.html\n",
      "विवरण स्क्र्याप गरिँदैछ: https://ekantipur.com/news/2025/09/12/202509121757675141.html\n",
      "विवरण स्क्र्याप गरिँदैछ: https://ekantipur.com/news/2025/09/12/202509121757670754.html\n",
      "\n",
      "स्क्र्यापिङ सम्पन्न भयो!\n",
      "जम्मा 5 वटा समाचार सफलतापूर्वक स्क्र्याप गरियो।\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>published_date</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>संविधानको धारा ६१ (४) अनुसार सुशीला कार्की अन्...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>भाद्र २७, २०८२ २०:३६</td>\n",
       "      <td>राष्ट्रपति रामचन्द्र पौडेलले सुशीला कार्कीलाई ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>प्रहरीका २८ थान हतियार लुटिए, खोजी गर्न ‘विशेष...</td>\n",
       "      <td>मातृका दाहाल</td>\n",
       "      <td>भाद्र २७, २०८२ १८:१०</td>\n",
       "      <td>जेन–जीले अगुवाई गरेको आन्दोलन पछि भड्किएको प्र...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>कान्तिपुर टेलिभिजनको नियमित प्रसारण सुरु</td>\n",
       "      <td>N/A</td>\n",
       "      <td>भाद्र २७, २०८२ १७:१३</td>\n",
       "      <td>कान्तिपुर टेलिभिजनको आजदेखि नियमित प्रसारण सुर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>राजनीतिक वार्ता र संकटकालको तयारी सँगसँगै</td>\n",
       "      <td>N/A</td>\n",
       "      <td>भाद्र २७, २०८२ १६:५०</td>\n",
       "      <td>जेन–जी आन्दोलनको मागअनुसार अन्तरिम सरकार बनाउन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>कानुनी शासनको जगमा निकास निकाल्न मानव अधिकार आ...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>भाद्र २७, २०८२ १५:३७</td>\n",
       "      <td>काठमाडौं– राष्ट्रिय मानव अधिकार आयोगले नयाँ सर...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        author  \\\n",
       "0  संविधानको धारा ६१ (४) अनुसार सुशीला कार्की अन्...           N/A   \n",
       "1  प्रहरीका २८ थान हतियार लुटिए, खोजी गर्न ‘विशेष...  मातृका दाहाल   \n",
       "2           कान्तिपुर टेलिभिजनको नियमित प्रसारण सुरु           N/A   \n",
       "3          राजनीतिक वार्ता र संकटकालको तयारी सँगसँगै           N/A   \n",
       "4  कानुनी शासनको जगमा निकास निकाल्न मानव अधिकार आ...           N/A   \n",
       "\n",
       "         published_date                                            summary  \n",
       "0  भाद्र २७, २०८२ २०:३६  राष्ट्रपति रामचन्द्र पौडेलले सुशीला कार्कीलाई ...  \n",
       "1  भाद्र २७, २०८२ १८:१०  जेन–जीले अगुवाई गरेको आन्दोलन पछि भड्किएको प्र...  \n",
       "2  भाद्र २७, २०८२ १७:१३  कान्तिपुर टेलिभिजनको आजदेखि नियमित प्रसारण सुर...  \n",
       "3  भाद्र २७, २०८२ १६:५०  जेन–जी आन्दोलनको मागअनुसार अन्तरिम सरकार बनाउन...  \n",
       "4  भाद्र २७, २०८२ १५:३७  काठमाडौं– राष्ट्रिय मानव अधिकार आयोगले नयाँ सर...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# आवश्यक लाइब्रेरीहरू import गर्ने\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# eKantipur को Base URL\n",
    "base_url = 'https://ekantipur.com'\n",
    "\n",
    "# अनुरोध पठाउँदा आफूलाई ब्राउजरको रूपमा चिनाउन User-Agent हेडरको प्रयोग\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "def scrape_article_detail(url):\n",
    "    \"\"\"\n",
    "    यो function ले एउटा समाचारको लिङ्क (URL) बाट विस्तृत जानकारी निकाल्छ।\n",
    "    \n",
    "    Args:\n",
    "        url (str): समाचारको पूरा लिङ्क।\n",
    "        \n",
    "    Returns:\n",
    "        dict: समाचारको प्रकाशित मिति र विस्तृत विवरण भएको dictionary।\n",
    "              यदि कुनै error आयो भने None return गर्छ।\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return None\n",
    "    print(f\"विवरण स्क्र्याप गरिँदैछ: {url}\")\n",
    "    try:\n",
    "        # URL मा HTTP GET request पठाउने (timeout र headers सहित)\n",
    "        response = requests.get(url, headers=headers, timeout=20)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # प्रकाशित मिति निकाल्ने\n",
    "        published_date_tag = soup.select_one('.published-at')\n",
    "        published_date = published_date_tag.get_text(strip=True).replace('प्रकाशित :', '').strip() if published_date_tag else 'N/A'\n",
    "        \n",
    "        # समाचारको पूरा विवरण (Content) निकाल्ने\n",
    "        content_paragraphs = []\n",
    "        # '.desc-content' भित्रका सबै <p> ट्यागहरू खोज्ने\n",
    "        paragraphs = soup.select('.desc-content p')\n",
    "        for p in paragraphs:\n",
    "            # <script> ट्याग नभएको र अनावश्यक 'gaEvent' text नभएको अनुच्छेद मात्र छान्ने\n",
    "            if not p.find('script'):\n",
    "                text = p.get_text(strip=True)\n",
    "                if text and 'gaEvent' not in text:\n",
    "                    content_paragraphs.append(text)\n",
    "        \n",
    "        content = '\\n'.join(content_paragraphs)\n",
    "        \n",
    "        return {\n",
    "            'published_date': published_date,\n",
    "            'content': content\n",
    "        }\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: समाचारको विवरण स्क्र्याप गर्न सकिएन ({url}) - {e}\")\n",
    "        return None\n",
    "\n",
    "def scrape_kantipur(limit=5):\n",
    "    \"\"\"\n",
    "    यो function ले eKantipur को समाचार पृष्ठबाट समाचारहरू स्क्र्याप गर्छ।\n",
    "    \n",
    "    Args:\n",
    "        limit (int): कतिवटा समाचार स्क्र्याप गर्ने भन्ने संख्या।\n",
    "        \n",
    "    Returns:\n",
    "        list: समाचारहरूको विवरण भएको list of dictionaries।\n",
    "    \"\"\"\n",
    "    news_url = f\"{base_url}/news\"\n",
    "    print(f\"eKantipur बाट {limit} वटा समाचार स्क्र्याप गरिँदैछ ({news_url})...\")\n",
    "    try:\n",
    "        response = requests.get(news_url, headers=headers, timeout=20)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        news_items = []\n",
    "        \n",
    "        # '.normal' class भएका सबै समाचारहरू select गर्ने\n",
    "        articles = soup.select('.normal')\n",
    "        \n",
    "        for article in articles[:limit]:\n",
    "            title_tag = article.select_one('.teaser h2 a')\n",
    "            summary_tag = article.select_one('.teaser p')\n",
    "            author_tag = article.select_one('.author a')\n",
    "\n",
    "            if title_tag:\n",
    "                title = title_tag.get_text(strip=True)\n",
    "                link = title_tag.get('href')\n",
    "                full_link = f\"{base_url}{link}\" if link and link.startswith('/') else link\n",
    "                summary = summary_tag.get_text(strip=True) if summary_tag else ''\n",
    "                author = author_tag.get_text(strip=True) if author_tag else 'N/A'\n",
    "                \n",
    "                news_items.append({\n",
    "                    'title': title,\n",
    "                    'link': full_link,\n",
    "                    'summary': summary,\n",
    "                    'author': author\n",
    "                })\n",
    "\n",
    "        # प्रत्येक समाचारको विस्तृत विवरण निकाल्ने\n",
    "        for item in news_items:\n",
    "            # Server मा धेरै चाप नदिन हरेक request को बिचमा १ सेकेन्ड पर्खने\n",
    "            time.sleep(1)\n",
    "            \n",
    "            details = scrape_article_detail(item['link'])\n",
    "            if details:\n",
    "                # निकालेको विवरणलाई update गर्ने\n",
    "                item.update(details)\n",
    "                    \n",
    "        return news_items\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: eKantipur स्क्र्याप गर्न सकिएन - {e}\")\n",
    "        return []\n",
    "\n",
    "# --- Jupyter Notebook मा चलाउने मुख्य भाग ---\n",
    "\n",
    "# ५ वटा समाचार स्क्र्याप गर्ने\n",
    "scraped_data = scrape_kantipur(limit=5)\n",
    "\n",
    "if scraped_data:\n",
    "    # स्क्र्याप गरिएको डाटालाई Pandas DataFrame मा बदल्ने\n",
    "    df = pd.DataFrame(scraped_data)\n",
    "    \n",
    "    print(\"\\nस्क्र्यापिङ सम्पन्न भयो!\")\n",
    "    print(f\"जम्मा {len(df)} वटा समाचार सफलतापूर्वक स्क्र्याप गरियो।\")\n",
    "    \n",
    "    # Jupyter Notebook मा DataFrame देखाउने\n",
    "    # DataFrame को स्तम्भहरू (columns) लाई व्यवस्थित गर्ने\n",
    "    display_columns = ['title', 'author', 'published_date', 'summary', 'link', 'content']\n",
    "    # DataFrame मा सबै स्तम्भहरू छन् कि छैनन् भनी सुनिश्चित गर्ने\n",
    "    final_df = df.reindex(columns=display_columns)\n",
    "    \n",
    "    display(final_df[['title', 'author', 'published_date', 'summary']])\n",
    "else:\n",
    "    print(\"\\nकुनै पनि समाचार स्क्र्याप गर्न सकिएन।\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34af732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
