{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "794db401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "'उहांको लागि चिया पनि 1,00 ल्याउनुहोस्, तरकारी मीठो छैन्। हामी सबै सँगै बस्छौं।'\n",
      "\n",
      "==================================================\n",
      "\n",
      "Final Text (Original Spelling Preserved):\n",
      "'चिया 1 , 00 ल्याउनुहोस् , तरकारी मीठो । बस्छौं ।'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# --- STEP 1: A FULLY STOPWORD SET ---\n",
    "\n",
    "NEPALI_STOPWORDS = {\n",
    "    # Pronouns & Determiners\n",
    "    'म', 'हामि', 'तँ', 'तिमि', 'तपाई', 'उ', 'उनि', 'उहाँ', 'यो', 'त्यो', 'यि', 'ति',\n",
    "    'मेरो', 'तिम्रो', 'तपाईको', 'हाम्रो', 'उसको', 'उनको', 'उहांको', 'यसको', 'त्यसको',\n",
    "    'मलाई', 'हामिलाई', 'तिमीलाई', 'तपाईलाई', 'उसलाई', 'उनलाई', 'उहाँलाई',\n",
    "    'आफु', 'आफ्नो', 'आफै', 'जो', 'जसले', 'जुन', 'कुनै', 'केहि', 'सबै', 'हरेक',\n",
    "    'कोहि', 'कसैले', 'कसैलाई', 'आफुलाई', 'आफ्ना', 'उक्त', 'सोहि', 'त्यहि', 'यहि',\n",
    "\n",
    "    # Conjunctions & Particles\n",
    "    'र', 'अनि', 'पनि', 'वा', 'तर', 'तथा', 'कि', 'भने', 'जब', 'तब', 'यदि', 'भन्दै', 'भन्ने',\n",
    "    'नै', 'त', 'नि', 'रे', 'खै', 'पो', 'है', 'एवं', 'समेत', 'साथै', 'वा', 'अर्थात',\n",
    "\n",
    "    # Postpositions (Case Markers)\n",
    "    'को', 'का', 'कि', 'रो', 'रा', 'रि', 'नो', 'ना', 'नि',\n",
    "    'मा', 'बाट', 'देखि', 'सम्म', 'तिर', 'तर्फ', 'संग', 'बिना', 'भित्र', 'बाहिर',\n",
    "    'माथि', 'तल', 'बीच', 'निम्ति', 'लागि', 'ले', 'लाई', 'द्वारा',\n",
    "\n",
    "    # Common Verbs (Auxiliary and simple forms)\n",
    "    'छ', 'छन', 'छौ', 'छु', 'छैन', 'छैनन', 'छैन्',\n",
    "    'हो', 'होइन', 'होला', 'हुन', 'हुने', 'हुन्छ', 'हुदैन',\n",
    "    'भयो', 'भएको', 'भए', 'भएका', 'भएर', 'भइ', 'भइसकेको', 'भएपछि', 'भएकाले', 'भइरहेको',\n",
    "    'थियो', 'थिए', 'थिइन', 'थिएन',\n",
    "    'गर्नु', 'गरेको', 'गर्यो', 'गरि', 'गर्दै', 'गर्ने', 'गरे', 'गरेका', 'गरिएको', 'गरेर', 'गर्दा', 'गर्न',\n",
    "    'दिनु', 'दिने', 'दियो', 'दिएको', 'दिए', 'दिदै',\n",
    "    'लिनु', 'लिने', 'लियो', 'लिएको', 'लिएर',\n",
    "    'हुनु', 'हुंदा', 'हुनाले',\n",
    "    'रहेको', 'रहेका', 'रहेछ',\n",
    "    'जानु', 'जाने', 'गएको', 'गए', 'गइ',\n",
    "    'आउनु', 'आउने', 'आएको', 'आए', 'आएर',\n",
    "    'पर्नु', 'पर्ने', 'परेको', 'परे',\n",
    "    'खानु', 'खाने',\n",
    "    'लाग्नु', 'लाग्ने', 'लाग्यो', 'लागेको',\n",
    "    'सक्नु', 'सक्ने', 'सकिने', 'सक्छ',\n",
    "    'बताए', 'बताउनु', 'भन्नु', 'भएछ',\n",
    "\n",
    "    # Common Adverbs, Adjectives & Quantifiers\n",
    "    'आज', 'भोलि', 'हिजो', 'अहिले', 'अब', 'फेरि', 'सधै', 'यहाँ', 'त्यहाँ', 'कहाँ',\n",
    "    'यसरि', 'त्यसरि', 'कसरि', 'धेरै', 'थोरै', 'अलि', 'निकै', 'एकदम', 'मात्र', 'मात्रै',\n",
    "    'पटक', 'दिन', 'रात', 'बर्ष', 'महिना', 'हप्ता', 'गते', 'पहिले', 'पछि', 'अघि', 'वरिपरि',\n",
    "    'अनुसार', 'बमोजिम', 'उक्त', 'सो', 'एक', 'दुई', 'तिन', 'चार', 'पाँच',\n",
    "    'राम्रो', 'नराम्रो', 'ठुलो', 'सानो', 'नयाँ', 'पुरानो', 'हरेक', 'प्रत्येक',\n",
    "    'करिब', 'झन्डै', 'लगभग', 'आजको', 'भोलिको', 'यस', 'त्यस', 'संगै',\n",
    "\n",
    "    # Question Words\n",
    "    'के', 'किन', 'कसले', 'कसलाई', 'कहिले', 'कसरि', 'कति', 'कुन',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# --- STEP 2: PRE-PROCESSING FUNCTION (Helper, Unchanged) ---\n",
    "def normalize_word_for_check(word):\n",
    "    \"\"\"\n",
    "    Normalizes a single word for checking against the stopword set.\n",
    "    \"\"\"\n",
    "    word = word.lower()\n",
    "    word = word.replace('ँ', 'ं')\n",
    "    word = word.replace('ी', 'ि')\n",
    "    word = word.replace('ू', 'ु')\n",
    "\n",
    "    # Remove any stray punctuation that might be attached to the word\n",
    "    punctuation_pattern = r'[।(),?!:\"\\'\\/-]'\n",
    "    word = re.sub(punctuation_pattern, '', word)\n",
    "    return word\n",
    "\n",
    "normalized_stopwords = [normalize_word_for_check(word) for word in NEPALI_STOPWORDS]\n",
    "\n",
    "# --- STEP 3: REWRITTEN MAIN FUNCTION ---\n",
    "def remove_nepali_stopwords(text, stopwords_set=normalized_stopwords):\n",
    "    \"\"\"\n",
    "    Takes a raw Nepali text, removes stopwords while preserving the\n",
    "    original spelling and punctuation of the remaining words.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The raw input Nepali text.\n",
    "        stopwords_set (set): A set of normalized stopwords to remove.\n",
    "        \n",
    "    Returns:\n",
    "        str: The text with stopwords removed, in its original form.\n",
    "    \"\"\"\n",
    "    # Pattern to find punctuation and split text around it, keeping the punctuation\n",
    "    # This ensures punctuation marks are treated as separate tokens.\n",
    "    tokenization_pattern = r'([।(),?!:\"\\'\\/-]|\\s+)'\n",
    "    \n",
    "    # Split the text by the pattern, which separates words and punctuation\n",
    "    original_tokens = re.split(tokenization_pattern, text)\n",
    "    \n",
    "    # List to hold the words/punctuation we want to keep\n",
    "    final_tokens = []\n",
    "    \n",
    "    for token in original_tokens:\n",
    "        # Ignore empty strings that can result from splitting\n",
    "        if not token.strip():\n",
    "            continue\n",
    "            \n",
    "        # Normalize the token just for the purpose of checking\n",
    "        normalized_token = normalize_word_for_check(token)\n",
    "        \n",
    "        # If the normalized token is not in the stopword list, keep the ORIGINAL token\n",
    "        if normalized_token not in stopwords_set:\n",
    "            final_tokens.append(token+\" \")\n",
    "            \n",
    "    # Join the final list of tokens back into a coherent string\n",
    "    return \"\".join(final_tokens).strip()\n",
    "\n",
    "# --- DEMONSTRATION OF THE CORRECTED LOGIC ---\n",
    "if __name__ == \"__main__\":\n",
    "    sample_text = \"उहांको लागि चिया पनि 1,00 ल्याउनुहोस्, तरकारी मीठो छैन्। हामी सबै सँगै बस्छौं।\"\n",
    "\n",
    "    print(f\"Original Text:\\n'{sample_text}'\")\n",
    "    \n",
    "    cleaned_text = remove_nepali_stopwords(sample_text)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    print(f\"Final Text (Original Spelling Preserved):\\n'{cleaned_text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4adbc27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56a5e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
